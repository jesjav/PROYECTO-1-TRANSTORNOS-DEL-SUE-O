# -*- coding: utf-8 -*-
"""REPLICACION DEL CODIGO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p9G_Na7Q2m7IvJgORuvSStUj14BbJQnO

1. Importación de librerías
"""

import numpy as np # Para operaciones numéricas y álgebra lineal
import pandas as pd # Para manipulación y análisis de datos
import matplotlib.pyplot as plt # Para visualización estática
import seaborn as sns # Para visualizaciones estadísticas
import plotly.express as px # Para visualizaciones interactivas
import warnings
warnings.filterwarnings('ignore') # Ignorar warnings durante la ejecución
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler, StandardScaler # Para preprocesamiento de datos
from sklearn.compose import ColumnTransformer # Para aplicar transformaciones a columnas específicas
from sklearn.pipeline import Pipeline # Para crear flujos de trabajo de Machine Learning
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_score # Para particionar datos y validación cruzada
from imblearn.over_sampling import SMOTE # Para manejo de datos desbalanceados
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix # Métricas de evaluación
from sklearn.linear_model import LogisticRegression # Modelo de regresión logística
import xgboost as xgb # Modelo XGBoost para Machine Learning

"""Propósito :
  
*    Librerías de análisis : numpy y pandas son esenciales para trabajar los datos
*   Visualización : matplotlib, seaborn, y plotly permiten crear gráficos para explorar de forma mas visual la informacion y creaci0on de tablas para ver patrones.
*   Preprocesamiento : sklearn.preprocessing incluye herramientas para codificar variables categóricas y estandarizar datos.
*   Elemento de la lista
*   Modelado : sklearn y xgboost proveen algoritmos de Machine Learning.
*    Manejo de datos : train_test_split, SMOTE, y métricas ayudan a preparar y evaluar modelos.

---

2. Lectura del dataset
"""

# Carga el archivo CSV en un DataFrame de pandas llamado df, permitiendo su manipulación y análisis.
df = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv')

"""OBSERVACION: en el codigo de kaggle  aparece asi "df = pd.read_csv('/kaggle/input/sleep-health-and-lifestyle-dataset/Sleep_health_and_lifestyle_dataset.csv')" pero ya que esta importado en colab solo agrege el titulo del archivo

---

3. Análisis Exploratorio de Datos (EDA)
"""

# Muestra las primeras 5 filas del dataset para entender su estructura.
df.head(5)

# muestra la dimension del data set
df.shape

"""hay 374 filas y 13 columnas"""

# muestra los tipos de dato
df.dtypes

# Resumen estadístico de variables numéricas.
df.describe()

# Identificar valores únicos en cada columna para detectar categorías, valores faltantes o inconsistencias
columns = [column for column in df.columns if column != 'Person ID']
for column in columns:
    unique_values = df[column].unique()
    print(f"Unique values in '{column}': {unique_values}")

# Reemplaza valores NaN en la columna Sleep Disorder con la categoría No Disorder, asumiendo que si falta registro eso implica ausencia de trastorno
df['Sleep Disorder'].fillna('No Disorder', inplace=True)

# Estandariza la categoría Normal a Normal Weight para coherencia con otras categorías (ej: "Overweight", "Obese") y para evitar erorres despues.
df['BMI Category'] = df['BMI Category'].replace({'Normal': 'Normal Weight'})

# Crea un histograma interactivo (con Plotly) para visualizar la relación entre Índice de Masa Corporal (IMC) y Trastornos del Sueño .
fig = px.histogram(
    data_frame=df,
    x='BMI Category',
    color='Sleep Disorder',
    title='Distribución de BMI Category según Trastornos del Sueño'
)
fig.show()

"""* Los obesos padecen insomnio y apnea del sueño.

* Muy pocas personas con sobrepeso no tienen trastornos del sueño.

* Muy pocas personas de peso normal padecen trastornos del sueño.
"""

# Visualizar la distribución de la calidad del sueño según el trastorno del sueño (Insomnia, Sleep Apnea, No Disorder).
fig = px.histogram(
    data_frame=df,
    x='Quality of Sleep',
    color='Sleep Disorder',
    title='Bar Chart of BMI Category Counts'
)
fig.show()

"""Error en el título : El título dice "BMI Category Counts" pero el eje X es "Quality of Sleep". Debería ser algo como "Quality of Sleep Distribution by Sleep Disorder" ."""

# Muestra la relación entre ocupación y trastornos del sueño .
fig = px.histogram(
    data_frame=df,
    x='Occupation',
    color='Sleep Disorder',
    title='Bar Chart of BMI Category Counts'
)
fig.show()

"""Nurse, Teacher, Salesperson/Sales Representative tienen más trastornos.

Este gráfico debería mostrar picos en esas ocupaciones para "Insomnia" o "Sleep Apnea".
"""

# Analizar si hay diferencias en la calidad del sueño entre hombres y mujeres.
# El gráfico de violín muestra la distribución de valores (medias, rangos, densidad).
color_palette = {'Male': 'lightblue', 'Female': 'lightcoral'}
plt.figure(figsize=(10, 6))
sns.violinplot(
    x='Gender',
    y='Quality of Sleep',
    data=df,
    palette=color_palette
)
plt.title('Distribution of Quality of Sleep by Gender', fontsize=16)
plt.xlabel('Gender', fontsize=12)
plt.ylabel('Quality of Sleep', fontsize=12)
plt.show()

# Dividir la columna 'Blood Pressure' (ej: "126/83") en dos columnas numéricas: Sistólica y Diastólica .
# Esto permite analizar ambas variables por separado.
df = pd.concat([df, df['Blood Pressure'].str.split('/', expand=True)], axis=1).drop('Blood Pressure', axis=1)
df = df.rename(columns={0: 'Systolic', 1: 'Diastolic'})
df['Systolic'] = df['Systolic'].astype(float)
df['Diastolic'] = df['Diastolic'].astype(float)

"""* La presión arterial alta (hipertensión) está asociada con trastornos del sueño como la apnea.
* Si las personas obesas tienen valores altos de presión arterial, esto podría explicar su mayor incidencia de trastornos.
"""

numeric_features = ['Age', 'Sleep Duration',
                    'Physical Activity Level',
                    'Heart Rate', 'Daily Steps', 'Systolic', 'Diastolic']
corr_matrix = df[numeric_features].corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title('Correlation Heatmap of data')
plt.show()

"""Proposito:
* dentificar correlaciones entre variables numéricas clave.
* Si la matriz muestra una correlación alta entre BMI Category (obesidad) y Sleep Apnea , esto respaldaría la observación del usuario.
* También podría mostrar que Stress Level y Quality of Sleep están correlacionados.
"""

# Eliminar 'Person ID' : Es una columna identificadora sin valor predictivo.
df.drop(columns=['Person ID'], inplace=True)
label_encoder = LabelEncoder()

#Codificar 'Sleep Disorder' : Convertir las categorías ("Insomnia", "No Disorder", "Sleep Apnea") en números (0, 1, 2) para usar en modelos de Machine Learning.
df['Sleep Disorder'] = label_encoder.fit_transform(df['Sleep Disorder'])
print(label_encoder.classes_)

"""* Esto prepara los datos para un modelo predictivo
* Predecir si una persona tiene un trastorno del sueño basado en variables como BMI Category , Occupation , etc.
* Validar si las observaciones (como que las personas obesas tienen más trastornos) son significativas estadísticamente.

---

4. Preprocesamiento
"""

# Separar características en dos grupos:
# Numéricas : Variables continuas o discretas (ej: Age, Sleep Duration).
# Categóricas : Variables con valores nominales o ordinales (ej: Gender, Occupation).
numeric_features = ['Age', 'Sleep Duration',
                   'Heart Rate', 'Daily Steps', 'Systolic', 'Diastolic']

categorical_features = ['Occupation', 'Quality of Sleep', 'Gender',
                       'Physical Activity Level', 'Stress Level', 'BMI Category']

"""Estas columnas se usan para predecir Sleep Disorder, que ya fue codificada previamente (Label Encoding).

En el análisis previo, observamos que variables como BMI Category y Occupation están relacionadas con trastornos del sueño.
"""

# Aplicar transformaciones diferentes a columnas numéricas y categóricas.
# RobustScaler : Estandariza características numéricas usando la mediana y el rango intercuartílico (menos sensible a outliers).
# OneHotEncoder : Codifica variables categóricas en binarios (ej: Gender → Gender_Male, Gender_Female).
  # drop='first': Evita colinealidad al eliminar una categoría (ej: solo Gender_Male, asumiendo Gender_Female como base).
  # sparse_output=False: Devuelve un array denso.
  # handle_unknown='ignore': Ignora nuevas categorías no vistas durante el entrenamiento.
preprocessor = ColumnTransformer(
    transformers=[
        ('num', RobustScaler(), numeric_features),
        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_features)
    ])

# X : Datos de entrada (todas las columnas excepto Sleep Disorder).
# y : Variable a predecir (Sleep Disorder).
X = df.drop(columns=['Sleep Disorder'])
y = df['Sleep Disorder']

"""* Sleep Disorder ya fue codificada previamente (Label Encoding), por lo que y es una columna numérica (0, 1, 2).
* Esto prepara los datos para modelos de clasificación.
"""

# Transformar X aplicando las transformaciones definidas en preprocessor.
X_preprocessed = preprocessor.fit_transform(X)

"""---

5. Manejo de Datos Desbalanceados-SMOTE(Técnica de Sobremuestreo de la Minoría Sintética)
"""

# Generar muestras sintéticas para las clases minoritarias (Insomnia, Sleep Apnea) para equilibrar el dataset.
smote = SMOTE(random_state=42)


X_smote, y_smote = smote.fit_resample(X_preprocessed, y)
X_smote.shape

"""La variable objetivo Sleep Disorder estaba desbalanceada (ej: "No Disorder" tenía 219 casos, mientras "Sleep Apnea" y "Insomnia" tenían ~75-80 casos).

SMOTE crea nuevas instancias interpolando entre muestras existentes de las clases minoritarias.

random_state=42: Asegura resultados reproducibles.

374 filas → SMOTE duplica/triplifica las clases minoritarias hasta alcanzar el tamaño de la clase mayoritaria ("No Disorder").

44 columnas corresponden a las características preprocesadas (escaladas y codificadas).

En los análisis previos, se observó que personas obesas o con ciertas ocupaciones (ej: "Nurse", "Teacher") tenían más trastornos del sueño. SMOTE ayuda a que el modelo no se sesgue hacia la clase mayoritaria ("No Disorder"), permitiendo aprender patrones de las clases minoritarias.
"""

# Dividir el dataset equilibrado en:
# Entrenamiento (75%) : Para entrenar el modelo.
# Prueba (25%) : Para evaluar su rendimiento en datos no vistos.


X_train, X_test, y_train, y_test = train_test_split(
    X_smote, y_smote,
    test_size=0.25,
    random_state=42
)

# test_size=0.25: 25% de los datos resampleados se usan para prueba.
# random_state=42: Reproducibilidad.

"""---

6. Entrenamiento del modelo
"""

# Crea una instancia del modelo de Regresión Logística , un algoritmo de clasificación binaria/multiclase que predice la probabilidad de pertenecer a una clase basándose en características lineales.
model_lr = LogisticRegression()

# Ajusta el modelo a los datos de entrenamiento (X_train, y_train).
# Calcula los coeficientes que maximizan la probabilidad de clasificar correctamente las muestras.
model_lr.fit(X_train, y_train)

# Genera predicciones para el conjunto de prueba (X_test).
y_pred_lr = model_lr.predict(X_test)

# Evaluar el rendimiento del modelo con métricas clave:
# Accuracy : Proporción de predicciones correctas.
# Precision : Proporción de verdaderos positivos entre predicciones positivas (importante para evitar falsos positivos).
# Recall : Proporción de verdaderos positivos correctamente identificados (importante para no perder casos reales).
# F1-score : Media armónica entre precision y recall.
accuracy_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr, average='weighted')
recall_lr = recall_score(y_test, y_pred_lr, average='weighted')
f1_lr = f1_score(y_test, y_pred_lr, average='weighted')

"""Ajusta métricas para clases desbalanceadas, dando más peso a clases con más muestras."""

# esrcibe las metricas
print(f'Accuracy: {accuracy_lr}')
print(f'Precision: {precision_lr}')
print(f'Recall: {recall_lr}')
print(f'F1-score: {f1_lr}')

# genera un repotrte de clasificacion
print(classification_report(y_test, y_pred_lr))

# genera una matriz sw confucion
cm_lr = confusion_matrix(y_test, y_pred_lr)
print('Confusion Matrix:')
print(cm_lr)

# Graficar la matriz de confusión mediante seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Crea una instancia del modelo XGBoost (eXtreme Gradient Boosting), un algoritmo de boosting basado en árboles de decisión.
model_xgb = xgb.XGBClassifier()

# Ajusta el modelo a los datos de entrenamiento (X_train, y_train).
# XGBoost construye múltiples árboles de decisión (ensembles) que corrijan los errores del modelo anterior.
model_xgb.fit(X_train, y_train)

# Genera predicciones para el conjunto de prueba (X_test).
y_pred = model_xgb.predict(X_test)
# Evalúa el rendimiento del modelo usando métricas estándar:
accuracy_xgb = accuracy_score(y_test, y_pred)
precision_xgb = precision_score(y_test, y_pred, average='weighted')
recall_xgb = recall_score(y_test, y_pred, average='weighted')
f1_xgb = f1_score(y_test, y_pred, average='weighted')

# muestra las metricas.
print(f'Accuracy: {accuracy_xgb}')
print(f'Precision: {precision_xgb}')
print(f'Recall: {recall_xgb}')
print(f'F1-score: {f1_xgb}')

# genera un repote de clasificacion.
print(classification_report(y_test, y_pred))

# genera una matriz de confusion
cm = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(cm)

# # Graficar la matriz de confusión mediante seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Crea un modelo de XGBoost con configuraciones específicas.
#Parámetros :
#random_state=42: Asegura resultados reproducibles.
#use_label_encoder=False: Evita advertencias al usar scikit-learn (XGBoost ahora usa su propio codificador).
#eval_metric='mlogloss': Métrica para evaluación en problemas multiclase (logarithmic loss).
xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')

# Dividir el dataset en 5 pliegues (folds) estratificados.
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Evaluar el rendimiento del modelo con validación cruzada .
scores = cross_val_score(xgb_model, X_smote, y_smote, cv=cv, scoring='accuracy')

# contendrá 5 valores de accuracy (uno por cada pliegue).
scores

from sklearn.ensemble import GradientBoostingClassifier

# Entrena un modelo de Gradient Boosting (otro algoritmo de ensemble).
gbm_clf = GradientBoostingClassifier(random_state=42)

# Evaluar el rendimiento del modelo GBM en el conjunto de prueba.
# entrena el modelo.
gbm_clf.fit(X_train, y_train)

# predicciones
y_pred = gbm_clf.predict(X_test)

# calcula las metricas
accuracy_gbm = accuracy_score(y_test, y_pred)
precision_gbm = precision_score(y_test, y_pred, average='weighted')
recall_gbm = recall_score(y_test, y_pred, average='weighted')
f1_gbm = f1_score(y_test, y_pred, average='weighted')

# Muestra precision, recall, F1-score y soporte por clase.
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Visualiza errores y aciertos entre clases.
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=['No Disorder', 'Sleep Apnea', 'Insomnia'], yticklabels=['No Disorder', 'Sleep Apnea', 'Insomnia'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Gradient Boosting Machine')
plt.show()

# muestra las metricas
print(f"Accuracy: {accuracy_gbm:.4f}")
print(f"Precision: {precision_gbm:.4f}")
print(f"Recall: {recall_gbm:.4f}")
print(f"F1 Score: {f1_gbm:.4f}")

# Importar el clasificador K-Nearest Neighbors (KNN) , un algoritmo basado en distancias que clasifica una muestra según la mayoría de sus k vecinos más cercanos.
from sklearn.neighbors import KNeighborsClassifier

# crea una instancia de KNN con k=5 (n_neighbors=5).
knn_clf = KNeighborsClassifier(n_neighbors=5)

# Entrena el modelo
knn_clf.fit(X_train, y_train)

# predicciones
y_pred = knn_clf.predict(X_test)

# Calcula metricas
accuracy_knn = accuracy_score(y_test, y_pred)
precision_knn = precision_score(y_test, y_pred, average='weighted')
recall_knn = recall_score(y_test, y_pred, average='weighted')
f1_knn = f1_score(y_test, y_pred, average='weighted')

# eporte de clasificacion
print("Classification Report:")
print(classification_report(y_test, y_pred))

# matriz de confussion
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Greens', fmt='d', xticklabels=['No Disorder', 'Sleep Apnea', 'Insomnia'], yticklabels=['No Disorder', 'Sleep Apnea', 'Insomnia'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - K-Nearest Neighbors')
plt.show()

# muestra las metricas
print(f"Accuracy: {accuracy_knn:.4f}")
print(f"Precision: {precision_knn:.4f}")
print(f"Recall: {recall_knn:.4f}")
print(f"F1 Score: {f1_knn:.4f}")

"""---

7. Comparacion de modelos
"""

# Importa funciones para calcular la curva ROC (roc_curve) y el área bajo la curva (AUC, auc).
# Estas métricas evalúan el rendimiento de los modelos en clasificación binaria/multiclase.
from sklearn.metrics import roc_curve, auc

# Crea una figura para la visualización.
fig_roc = plt.figure(figsize=(10, 8))
models = ['Gradient Boosting Machine', 'K-Nearest Neighbors', 'Logistic Regression', 'XGBoost']

# Recorre los 4 modelos entrenados (gbm_clf, knn_clf, model_lr, model_xgb).
# idx es el índice para acceder al nombre del modelo en la lista models.
for idx, model in enumerate([gbm_clf, knn_clf, model_lr, model_xgb]):
    if model == knn_clf:
        y_scores = model.predict_proba(X_test)
        fpr, tpr, _ = roc_curve(y_test, y_scores[:, 1], pos_label=1)
    else:
        y_scores = model.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_scores, pos_label=1)

    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'{models[idx]} (AUC = {roc_auc:.2f})')

# Agrega una línea diagonal para comparar con un modelo que adivina al azar (AUC=0.5).
# Si un modelo está por debajo de esta línea, su rendimiento es peor que el azar.
plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Random Guessing')


# Etiqueta ejes, título, leyenda y cuadrícula para mejorar la legibilidad.
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

"""---

8. Guardar modelo
"""

# Guardar el modelo entrenado (model_xgb) y el preprocesador (preprocessor) para usarlos en el futuro sin necesidad de reentrenar.
# pickle : Librería de Python para serializar/deserializar objetos.
# Archivo .sav : Extensión común para modelos guardados en Python.

import pickle
with open("Model_Prediction.sav", "wb") as f:
    pickle.dump(model_xgb, f)
with open('preprocessor.sav', 'wb') as f:
    pickle.dump(preprocessor, f)

# Para cargar el modelo guardado con pickle
model_xgb = pickle.load(open('Model_Prediction.sav', 'rb'))